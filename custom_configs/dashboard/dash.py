from datetime import datetime
import json
import os
from pathlib import Path

import bcrypt
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import shap
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
import streamlit as st
from streamlit_autorefresh import st_autorefresh

st.set_page_config(layout="wide")
CONFIG_PATH = "config.json"
PROJECT_ID = "dismissial_predict"
LOG_CSV_PATH = "auth_log.csv"

COLUMNS_TO_SHOW = [
    # üéØ –¶–µ–ª–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    "–¥–∞—Ç–∞_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è",
    # üë§ –õ–∏—á–Ω–æ–µ
    "–¥–∞—Ç–∞_—Ä–æ–∂–¥–µ–Ω–∏—è",
    "–≤–æ–∑—Ä–∞—Å—Ç",
    "–ø–æ–ª",
    # üë®‚Äçüë©‚Äçüëß‚Äçüë¶ –°–µ–º—å—è
    "—á–∏—Å–ª–æ_–¥–µ—Ç–µ–π",
    "—Å—Ä–µ–¥–Ω–∏–π_–≤–æ–∑—Ä–∞—Å—Ç_–¥–µ—Ç–µ–π",
    "–¥–µ—Ç–∏_–º–∞–ª—å—á–∏–∫–∏",
    "–¥–µ—Ç–∏_–¥–µ–≤–æ—á–∫–∏",
    "–µ—Å—Ç—å_–º–∞–ª–µ–Ω—å–∫–∏–µ_–¥–µ—Ç–∏",
    # üè¢ –†–∞–±–æ—á–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    "–¥–∞—Ç–∞_–ø—Ä–∏–µ–º–∞_–≤_1—Å",
    "—Å—Ç–∞–∂",
    "—Ç–µ–∫—É—â–∞—è_–¥–æ–ª–∂–Ω–æ—Å—Ç—å_–Ω–∞_–ø–æ—Ä—Ç–∞–ª–µ",
    "–∫–∞—Ç–µ–≥–æ—Ä–∏—è",
    "–±–µ",
    "–æ—Ç–¥–µ–ª",
    "id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è",
    "–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–µ",
    # üìÖ –°–æ–±—ã—Ç–∏—è
    "—Å–∫–æ—Ä–æ_–¥—Ä",
    "—Å–∫–æ—Ä–æ_–≥–æ–¥–æ–≤—â–∏–Ω–∞_–ø—Ä–∏–µ–º–∞",
    # üí∞ –§–∏–Ω–∞–Ω—Å—ã –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
    "–∑–ø_–Ω–∞_—Å—Ä_–∑–ø_–ø–æ_–∫–æ–º–ø–∞–Ω–∏–∏",
    "–∑–ø_–∫_–≤–æ–∑—Ä–∞—Å—Ç—É",
    "–∑–ø_–∫_—Å—Ç–∞–∂—É",
]

info_file = Path(
    "/home/root6/python/dismissal_predict_v2/data/processed/main_all_history_do_not_tuch.csv"
)


def log_auth_event_csv(login: str, status: str):
    import csv
    from datetime import datetime

    log_path = "auth_log.csv"
    headers = ["datetime", "status", "login"]
    row = [datetime.now().strftime("%Y-%m-%d %H:%M:%S"), status, login]

    write_header = not os.path.exists(log_path)
    with open(log_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(headers)
        writer.writerow(row)


def handle_auth():
    placeholder = st.empty()

    if "login_stage" not in st.session_state:
        st.session_state.login_stage = "username"
    if "login" not in st.session_state:
        st.session_state.login = ""
    if "password_attempts" not in st.session_state:
        st.session_state.password_attempts = 0

    if st.session_state.login_stage == "username":
        with placeholder.container():
            st.title("üîê –í—Ö–æ–¥")
            with st.form("login_form"):
                login_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ª–æ–≥–∏–Ω")
                submit_login = st.form_submit_button("–í–≤–æ–¥")

            if submit_login:
                if login_input not in allowed_users:
                    log_auth_event_csv(login_input, "fail_unknown_user")
                    st.error("‚õî –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
                else:
                    st.session_state.login = login_input
                    st.session_state.login_stage = "password"
                    st.rerun()
        st.stop()

    user_record = next(
        (u for u in config["users"] if u["username"] == st.session_state.login), None
    )

    if user_record and "password" in user_record:
        if st.session_state.login_stage != "authenticated":
            with placeholder.container():
                st.title("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
                with st.form("password_form"):
                    password_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å", type="password")
                    submit_pass = st.form_submit_button("–í–≤–æ–¥")

                if submit_pass:
                    if bcrypt.checkpw(
                        password_input.encode(), user_record["password"].encode("utf-8")
                    ):
                        st.session_state.login_stage = "authenticated"
                        log_auth_event_csv(st.session_state.login, "success")
                        placeholder.empty()
                        st.rerun()
                    else:
                        st.session_state.password_attempts += 1
                        log_auth_event_csv(st.session_state.login, "fail_wrong_password")
                        st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
            st.stop()

    elif user_record is None:
        with placeholder.container():
            st.title("üõ° –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä–æ–ª—è")
            with st.form("new_password_form"):
                new_pass1 = st.text_input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø–∞—Ä–æ–ª—å", type="password")
                new_pass2 = st.text_input("–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–∞—Ä–æ–ª—å", type="password")
                submit_new = st.form_submit_button("–°–æ–∑–¥–∞—Ç—å")

            if submit_new:
                if new_pass1 != new_pass2:
                    st.error("‚ùå –ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
                else:
                    hashed_pw = bcrypt.hashpw(new_pass1.encode(), bcrypt.gensalt()).decode()
                    config["users"].append(
                        {"username": st.session_state.login, "password": hashed_pw}
                    )
                    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                        json.dump(config, f, ensure_ascii=False, indent=2)

                    log_auth_event_csv(st.session_state.login, "created_new_password")
                    st.success("‚úÖ –ü–∞—Ä–æ–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
                    st.session_state.login_stage = "authenticated"
                    placeholder.empty()
                    st.rerun()
        st.stop()


def render_user_card(user: dict):
    def safe_get(key, fmt=None, suffix=""):
        val = user.get(key)
        if pd.isna(val):
            return "nan"
        try:
            if fmt:
                return fmt.format(val) + suffix
            return str(val) + suffix
        except:
            return "nan"

    def safe_bool(key):
        val = user.get(key)
        return "–î–∞" if val else "–ù–µ—Ç"

    st.markdown("### üë§ –ö–∞—Ä—Ç–æ—á–∫–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞")
    st.markdown(
        f"""
    <b>üìå –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è</b><br>
    –£–≤–æ–ª–µ–Ω: {safe_get("–¥–∞—Ç–∞_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è")}<br>
    –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {safe_get("–¥–∞—Ç–∞_—Ä–æ–∂–¥–µ–Ω–∏—è")} &nbsp;&nbsp;&nbsp;
    –ü–æ–ª: {safe_get("–ø–æ–ª")} &nbsp;&nbsp;&nbsp;
    –í–æ–∑—Ä–∞—Å—Ç: {safe_get("–≤–æ–∑—Ä–∞—Å—Ç", "{}")}<br><br>

    <b>üë®‚Äçüë©‚Äçüëß‚Äçüë¶ –°–µ–º—å—è</b><br>
    –î–µ—Ç–µ–π: {safe_get("—á–∏—Å–ª–æ_–¥–µ—Ç–µ–π")} &nbsp;&nbsp;&nbsp;
    –ú–∞–ª—å—á–∏–∫–∏: {safe_get("–¥–µ—Ç–∏_–º–∞–ª—å—á–∏–∫–∏")} &nbsp;&nbsp;&nbsp;
    –î–µ–≤–æ—á–∫–∏: {safe_get("–¥–µ—Ç–∏_–¥–µ–≤–æ—á–∫–∏")} &nbsp;&nbsp;&nbsp;
    –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–µ—Ç–∏ (<=5): {safe_bool("–µ—Å—Ç—å_–º–∞–ª–µ–Ω—å–∫–∏–µ_–¥–µ—Ç–∏")}<br><br>

    <b>üíº –†–∞–±–æ—Ç–∞</b><br>
    –î–∞—Ç–∞ –ø—Ä–∏—ë–º–∞: {safe_get("–¥–∞—Ç–∞_–ø—Ä–∏–µ–º–∞_–≤_1—Å")} &nbsp;&nbsp;&nbsp;<br>
    –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å: {safe_get("id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è")}<br>
    –°—Ç–∞–∂: {safe_get("—Å—Ç–∞–∂", "{:.1f}")}<br>
    –î–æ–ª–∂–Ω–æ—Å—Ç—å: {safe_get("—Ç–µ–∫—É—â–∞—è_–¥–æ–ª–∂–Ω–æ—Å—Ç—å_–Ω–∞_–ø–æ—Ä—Ç–∞–ª–µ")}<br>
    –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {safe_get("–∫–∞—Ç–µ–≥–æ—Ä–∏—è")} &nbsp;&nbsp;&nbsp;<br>
    –ë–ï: {safe_get("–±–µ")}<br>
    –û—Ç–¥–µ–ª: {safe_get("–æ—Ç–¥–µ–ª")}<br>
    –ü–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–µ: {safe_get("–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–µ")}<br><br>

    <b>üìÖ –°–æ–±—ã—Ç–∏—è</b><br>
    –°–∫–æ—Ä–æ –î–†: {safe_bool("—Å–∫–æ—Ä–æ_–¥—Ä")} &nbsp;&nbsp;&nbsp;<br>
    –°–∫–æ—Ä–æ –≥–æ–¥–æ–≤—â–∏–Ω–∞ –ø—Ä–∏—ë–º–∞: {safe_bool("—Å–∫–æ—Ä–æ_–≥–æ–¥–æ–≤—â–∏–Ω–∞_–ø—Ä–∏–µ–º–∞")}<br><br>

    <b>üí∞ –§–∏–Ω–∞–Ω—Å—ã</b><br>
    –ó–ü –∫ —Å—Ä–µ–¥–Ω–µ–π –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏: {safe_get("–∑–ø_–Ω–∞_—Å—Ä_–∑–ø_–ø–æ_–∫–æ–º–ø–∞–Ω–∏–∏", "{:.2f}")}<br><br>
    """,
        unsafe_allow_html=True,
    )


def plot_top_departments_by_risk(df_all: pd.DataFrame, latest_date: str, info_file: Path):
    st.subheader("üìä –¢–æ–ø-10 –æ—Ç–¥–µ–ª–æ–≤ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —Ä–∏—Å–∫—É —É–≤–æ–ª—å–Ω–µ–Ω–∏—è")

    if not info_file.exists():
        st.warning("–§–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ info_file
        df_info = pd.read_csv(info_file)
        df_info.columns = [str(col).strip().lower() for col in df_info.columns]

        if "id" not in df_info.columns:
            st.error("–í info_file –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'id'")
            return
        if "–æ—Ç–¥–µ–ª" not in df_info.columns:
            st.error("–í info_file –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–æ—Ç–¥–µ–ª'")
            return

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ id –∫ —Å—Ç—Ä–æ–∫–∞–º ‚Üí float (—Å–Ω–∞—á–∞–ª–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ merge)
        df_info["id"] = df_info["id"].astype(str).str.strip().str.lower()
        df_all["id"] = df_all["id"].astype(str).str.strip().str.lower()

        if latest_date not in df_all.columns:
            st.error(f"–ö–æ–ª–æ–Ω–∫–∞ '{latest_date}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ df_all.")
            return

        df_all["id"] = df_all["id"].astype(float)
        df_info["id"] = df_info["id"].astype(float)

        # –°–ª–∏—è–Ω–∏–µ
        merged_df = df_all.merge(df_info[["id", "–æ—Ç–¥–µ–ª"]], how="left", on="id")

        # –£–¥–∞–ª–∏–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –æ—Ç–¥–µ–ª–∞ –∏–ª–∏ –±–µ–∑ latest_date
        merged_df = merged_df.dropna(subset=["–æ—Ç–¥–µ–ª", latest_date])

        if merged_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º–∏ –æ—Ç–¥–µ–ª–∞–º–∏ –∏ —Ä–∏—Å–∫–∞–º–∏.")
            return

        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
        agg_df = (
            merged_df.groupby("–æ—Ç–¥–µ–ª")[latest_date]
            .mean()
            .sort_values(ascending=False)
            .head(10)
            .reset_index()
        )
        agg_df.columns = ["–û—Ç–¥–µ–ª", "–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫"]

        if agg_df.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            return

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ matplotlib
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.barh(agg_df["–û—Ç–¥–µ–ª"], agg_df["–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫"], color="skyblue")
        ax.invert_yaxis()
        ax.set_xlabel("–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è")
        ax.set_title("–¢–æ–ø-10 –æ—Ç–¥–µ–ª–æ–≤ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —Ä–∏—Å–∫—É —É–≤–æ–ª—å–Ω–µ–Ω–∏—è")
        plt.tight_layout()

        st.pyplot(fig)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")


def show_critical_department_profiles(
    df_all: pd.DataFrame, info_file: Path, latest_date: str, path_all: Path
):
    st.subheader("üè¢ –ü—Ä–æ—Ñ–∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–¥–µ–ª–æ–≤")

    if not info_file.exists():
        st.warning("–§–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    try:
        df_info = pd.read_csv(info_file)
        df_info.columns = [str(c).strip().lower() for c in df_info.columns]
        df_info["id"] = df_info["id"].astype(str).str.strip().str.lower()
        df_info["—Ñ–∏–æ"] = df_info["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

        df_all["id"] = df_all["id"].astype(str).str.strip().str.lower()
        df_all["—Ñ–∏–æ"] = df_all["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

        top_departments_df = (
            df_all[["id", "—Ñ–∏–æ", latest_date]]
            .merge(df_info[["id", "–æ—Ç–¥–µ–ª", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å"]], how="left", on="id")
            .dropna(subset=["–æ—Ç–¥–µ–ª", latest_date])
        )

        avg_risk_by_dept = (
            top_departments_df.groupby("–æ—Ç–¥–µ–ª")[latest_date]
            .mean()
            .sort_values(ascending=False)
            .head(10)
            .reset_index()
            .rename(columns={latest_date: "—Å—Ä–µ–¥–Ω–∏–π_—Ä–∏—Å–∫"})
        )

        selected_dept = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª –∏–∑ —Ç–æ–ø-10 –ø–æ —Ä–∏—Å–∫—É:",
            avg_risk_by_dept["–æ—Ç–¥–µ–ª"],
            index=0,
        )

        dept_df = top_departments_df[top_departments_df["–æ—Ç–¥–µ–ª"] == selected_dept].copy()
        dept_df = dept_df.dropna(subset=[latest_date])

        st.markdown(f"#### üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –≤ –æ—Ç–¥–µ–ª–µ: *{selected_dept}*")

        fig_dept = px.histogram(
            dept_df,
            x=latest_date,
            nbins=20,
            title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è ‚Äì {selected_dept}",
            labels={latest_date: "–†–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è"},
        )
        fig_dept.update_layout(xaxis_title="–†–∏—Å–∫", yaxis_title="–ß–∏—Å–ª–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
        st.plotly_chart(fig_dept, use_container_width=True)

        st.markdown("#### üë• –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –≤ –æ—Ç–¥–µ–ª–µ")

        try:
            full_df = pd.read_excel(path_all)
            full_df.columns = [c.strip().lower() for c in full_df.columns]
            full_df["—Ñ–∏–æ"] = full_df["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

            dept_df["—Ñ–∏–æ"] = dept_df["—Ñ–∏–æ"].astype(str).str.strip().str.lower()
            dept_df = dept_df.merge(
                full_df[["—Ñ–∏–æ", "—É–≤–æ–ª–µ–Ω", "–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è"]],
                how="left",
                on="—Ñ–∏–æ",
            )
        except Exception as e:
            st.warning(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–∫—Ç/–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {e}")

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –ø–æ id
        dept_df = dept_df.drop_duplicates(subset="id")

        # –£–±–∏—Ä–∞–µ–º —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        dept_df = dept_df[dept_df["—É–≤–æ–ª–µ–Ω"] != 1]

        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        dept_df_display = (
            dept_df[["—Ñ–∏–æ", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å", latest_date]]
            .rename(
                columns={
                    "—Ñ–∏–æ": "–§–ò–û",
                    "–¥–æ–ª–∂–Ω–æ—Å—Ç—å": "–î–æ–ª–∂–Ω–æ—Å—Ç—å",
                    latest_date: "–†–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è",
                }
            )
            .sort_values("–†–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è", ascending=False)
            .reset_index(drop=True)
        )

        st.dataframe(dept_df_display, use_container_width=True)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ—Ñ–∏–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–¥–µ–ª–æ–≤: {e}")


def run_dashboard(excel_file: str, title: str):
    if not Path(excel_file).exists():
        st.error(f"–§–∞–π–ª {excel_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    df = pd.read_excel(excel_file)
    df.columns = [str(col).strip().lower() for col in df.columns]

    # –û–ø—Ä–µ–¥–µ–ª–∏–º —Å—Ç–æ–ª–±—Ü—ã-–¥–∞—Ç—ã –∏ –ø—Ä–∏–≤–µ–¥–µ–º –∫ float
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤-–¥–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–¥.–º–º.–≥–≥–≥–≥

    date_cols = []
    new_columns = []

    for col in df.columns:
        try:
            parsed = datetime.strptime(col.strip(), "%d.%m.%Y")
            date_cols.append(col.strip())
            new_columns.append(col.strip())
        except ValueError:
            new_columns.append(col)

    df.columns = new_columns

    for col in date_cols:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", ".")
            .str.replace(" ", "")
            .str.replace(r"[^\d.]", "", regex=True)
        )
        df[col] = pd.to_numeric(df[col], errors="coerce")

    sorted_date_cols = sorted(date_cols, key=lambda d: pd.to_datetime(d, dayfirst=True))
    latest_date = sorted_date_cols[-1]

    st.subheader(f"–§–∏–ª—å—Ç—Ä—ã ({title})")
    st.info(
        """
            –í —Ç–∞–±–ª–∏—Ü–µ —Å–æ–±—Ä–∞–Ω—ã –≤—Å–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ —É–≤–æ–ª–µ–Ω–Ω—ã–µ:\n
            –§–∞–∫—Ç: 1 - –≤–∫–ª—é—á–∞–µ—Ç —É–≤–æ–ª–µ–Ω–Ω—ã—Ö, 0 - –≤–∫–ª—é—á–∞–µ—Ç –Ω–µ —É–≤–æ–ª–µ–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Å–Ω—è—Ç—å –≤—ã–±–æ—Ä, —Ç–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç.\n
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 1 - –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞, —á—Ç–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ —É–≤–æ–ª–∏—Ç—Å—è, 0 - –Ω–µ —É–≤–æ–ª–∏—Ç—Å—è.\n
            """
    )
    col_fact, col_pred = st.columns(2)

    with col_fact:
        st.markdown("**–§–∞–∫—Ç:**")
        show_0_dismissed = st.checkbox("–ù–µ —É–≤–æ–ª–µ–Ω (0)", value=True, key=f"dismissed_0_{title}")
        show_1_dismissed = st.checkbox("–£–≤–æ–ª–µ–Ω (1)", value=True, key=f"dismissed_1_{title}")

    with col_pred:
        st.markdown("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:**")
        show_0_pred = st.checkbox("–ù–µ—Ç —É–≤–æ–ª—å–Ω–µ–Ω–∏—è (0)", value=True, key=f"pred_0_{title}")
        show_1_pred = st.checkbox("–ï—Å—Ç—å —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (1)", value=True, key=f"pred_1_{title}")

    dismissed_values = []
    if show_0_dismissed:
        dismissed_values.append(0)
    if show_1_dismissed:
        dismissed_values.append(1)

    pred_values = []
    if show_0_pred:
        pred_values.append(0)
    if show_1_pred:
        pred_values.append(1)

    filtered_df = df[
        df["—É–≤–æ–ª–µ–Ω"].isin(dismissed_values) & df["–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è"].isin(pred_values)
    ]

    if info_file.exists():
        df_info = pd.read_csv(info_file)

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –§–ò–û –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
        df_info["—Ñ–∏–æ"] = df_info["—Ñ–∏–æ"].astype(str).str.strip().str.lower()
        filtered_df.loc[:, "—Ñ–∏–æ"] = filtered_df["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

        # –ú–µ—Ä–∂ –ø–æ –§–ò–û
        filtered_df = filtered_df.merge(df_info[["—Ñ–∏–æ", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å"]], how="left", on="—Ñ–∏–æ")

        # –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π: —É–±–æ—Ä—â–∏—Ü–∞, –æ—Ñ–∏—Ü–µ—Ä
        filtered_df = filtered_df[
            ~filtered_df["–¥–æ–ª–∂–Ω–æ—Å—Ç—å"]
            .astype(str)
            .str.strip()
            .str.lower()
            .isin(["–¥–æ–ª–∂–Ω–æ—Å—Ç—å_1", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å_2"])
        ]
    else:
        st.warning("–§–∞–π–ª —Å –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º –ø—Ä–æ–ø—É—â–µ–Ω–∞.")

    if filtered_df.empty:
        st.info("–ù–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    st.subheader(f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å —Ä–∏—Å–∫–æ–º —É–≤–æ–ª—å–Ω–µ–Ω–∏—è –Ω–∞ {latest_date}")
    st.info(
        """
            –í—ã–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ —Ä–∞–∑–≤–µ—Ä–Ω–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –Ω–∏–∂–µ.
        """
    )
    search_name_tab = st.text_input("üîç –ü–æ–∏—Å–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ø–æ –§–ò–û", key=f"search_{title}")
    if search_name_tab:
        filtered_df = filtered_df[filtered_df["—Ñ–∏–æ"].str.contains(search_name_tab)]

    top_risk_df = (
        filtered_df.sort_values(by=latest_date, ascending=False)[["—Ñ–∏–æ", latest_date]]
        .drop_duplicates(subset="—Ñ–∏–æ", keep="first")  # <-- —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏
        .rename(columns={latest_date: "—Ä–∏—Å–∫_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è"})
        .reset_index(drop=True)
    )

    gb = GridOptionsBuilder.from_dataframe(top_risk_df)
    gb.configure_selection("single", use_checkbox=False)
    gb.configure_grid_options(autoSizeColumns=True, domLayout="normal")  # –¥–ª—è —Å–∫—Ä–æ–ª–ª–∞
    grid_options = gb.build()

    grid_response = AgGrid(
        top_risk_df,
        gridOptions=grid_options,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        height=500,
        allow_unsafe_jscode=True,
        theme="streamlit",
        fit_columns_on_grid_load=True,
    )

    selected_rows = grid_response.get("selected_rows", [])
    if isinstance(selected_rows, pd.DataFrame) and not selected_rows.empty:
        selected_fio = selected_rows.iloc[0]["—Ñ–∏–æ"]
    else:
        selected_fio = None

    if selected_fio:
        emp = df[df["—Ñ–∏–æ"] == selected_fio].iloc[0]
        st.subheader(f"–ü—Ä–æ—Ñ–∏–ª—å: {selected_fio.title()}")
        st.metric("–ò—Ç–æ–≥–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–≤–æ–ª—å–Ω–µ–Ω–∏—è", f"{emp[latest_date]*100:.1f}%")

        st.write("–î–∏–Ω–∞–º–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
        prob_series = pd.Series(emp[sorted_date_cols].values, index=sorted_date_cols)
        prob_series.index = pd.to_datetime(prob_series.index, dayfirst=True, errors="coerce")
        prob_series = prob_series.sort_index()
        st.line_chart(prob_series)

        if info_file.exists():
            info_df = pd.read_csv(info_file)

            info_df["—Ñ–∏–æ"] = info_df["—Ñ–∏–æ"].str.strip().str.lower()
            fio_lower = selected_fio.strip().lower()

            row_info = info_df[info_df["—Ñ–∏–æ"] == fio_lower]

            if not row_info.empty:
                # –ö–æ–ø–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏
                info_display = row_info[COLUMNS_TO_SHOW].iloc[0].copy()

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
                manager_id = info_display["id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è"]

                if pd.isna(manager_id):
                    manager_label = "nan"
                elif manager_id == -1:
                    manager_label = "-1 (nan)"
                else:
                    # –ò—â–µ–º —Ñ–∏–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ø–æ –µ–≥–æ id
                    manager_fio = info_df.loc[info_df["id"] == manager_id, "—Ñ–∏–æ"].values  # type: ignore
                    if len(manager_fio) > 0:
                        manager_label = f"{manager_id} ({manager_fio[0].title()})"
                    else:
                        manager_label = str(manager_id)

                # –ó–∞–º–µ–Ω—è–µ–º id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –Ω–∞ —Ñ–æ—Ä–º–∞—Ç —Å –§–ò–û
                info_display["id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è"] = manager_label

                # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
                user_info_dict = info_display.to_dict()
                render_user_card(user_info_dict)

            else:
                st.info("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ –≤ —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        else:
            st.warning("–§–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        shap_file = (
            Path("/home/root6/python/dismissal_predict_v2/data/results/result_top_shap.csv")
            if title == "top"
            else Path("/home/root6/python/dismissal_predict_v2/data/results/result_all_shap.csv")
        )

        if shap_file.exists():
            shap_df = pd.read_csv(shap_file)
            row = shap_df[shap_df["—Ñ–∏–æ"] == selected_fio]
            if not row.empty:
                shap_row = row.iloc[0].drop("—Ñ–∏–æ")
                top_factors = shap_row.abs().sort_values(ascending=False).head(5)
                top_features = top_factors.index
                top_values = shap_row[top_features]

                st.subheader("–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ (–ø–æ SHAP):")

                col_left, col_right = st.columns([1.5, 3])

                with col_left:
                    fig, ax = plt.subplots(figsize=(6, 3.5))
                    bars = ax.barh(
                        top_features[::-1],
                        top_values[::-1],
                        color=["red" if val > 0 else "blue" for val in top_values[::-1]],
                    )
                    ax.axvline(0, color="black", linewidth=0.8)
                    ax.set_xlabel("SHAP –∑–Ω–∞—á–µ–Ω–∏–µ (–≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–∏—Å–∫)", fontsize=10)
                    ax.set_ylabel("–ü—Ä–∏–∑–Ω–∞–∫", fontsize=10)
                    ax.set_title("–¢–û–ü —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ –≤–ª–∏—è–Ω–∏—é", fontsize=11)
                    ax.tick_params(axis="both", labelsize=9)
                    fig.tight_layout()

                    st.pyplot(fig, clear_figure=True)
            else:
                st.info(f"SHAP-—Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞: {selected_fio}")
        else:
            st.info("–§–∞–π–ª —Å SHAP-—Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.")


def run_dashboard_summary(path_all, shap_path_all):
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_all = pd.read_excel(path_all)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    df_all.columns = [str(c).strip().lower() for c in df_all.columns]
    df_all["—Ñ–∏–æ"] = df_all["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã
    date_cols = [col for col in df_all.columns if col.count(".") == 2 and col[:2].isdigit()]
    sorted_date_cols = sorted(date_cols, key=lambda d: pd.to_datetime(d, dayfirst=True))
    latest_date = sorted_date_cols[-1]

    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
    fig = px.histogram(df_all, x=latest_date, nbins=50, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è")
    fig.update_layout(xaxis_title="–†–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è", yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
    st.plotly_chart(fig, use_container_width=True)

    # SHAP-—Ñ–∞–∫—Ç–æ—Ä—ã
    st.subheader("–ê–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞ (SHAP)")
    if shap_path_all.exists():
        shap_all = pd.read_csv(shap_path_all)

        shap_all.drop(columns=["—Ñ–∏–æ"], inplace=True, errors="ignore")

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        mean_positive = (
            shap_all[shap_all > 0].mean().dropna().sort_values(ascending=False).head(10)
        )
        mean_negative = shap_all[shap_all < 0].mean().dropna().sort_values().head(10)

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**–¢–û–ü-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (SHAP > 0)**")
            fig1 = px.bar(
                mean_positive.reset_index(),
                x="index",
                y=0,
                labels={"index": "–§–∞–∫—Ç–æ—Ä", "0": "SHAP –∑–Ω–∞—á–µ–Ω–∏–µ"},
            )
            fig1.update_layout(xaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            st.markdown("**–¢–û–ü-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–∞ –Ω–µ—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (SHAP < 0)**")
            fig2 = px.bar(
                mean_negative.reset_index(),
                x="index",
                y=0,
                labels={"index": "–§–∞–∫—Ç–æ—Ä", "0": "SHAP –∑–Ω–∞—á–µ–Ω–∏–µ"},
            )
            fig2.update_layout(xaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig2, use_container_width=True)

        with col3:
            st.markdown("**–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ (–ø–æ SHAP)**")
            top_features = (
                shap_all.abs().mean().sort_values(ascending=False).head(10).index.tolist()
            )
            shap_sample = shap_all[top_features]

            fig_summary, ax = plt.subplots(figsize=(8, 6))
            shap.summary_plot(
                shap_sample.values,
                features=shap_sample,
                feature_names=top_features,
                plot_type="dot",
                show=False,
            )
            st.pyplot(fig_summary)
    else:
        st.warning("–§–∞–π–ª SHAP-—Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    plot_top_departments_by_risk(df_all, latest_date, info_file)
    show_critical_department_profiles(df_all, info_file, latest_date, path_all)


if "user_info_json" not in st.session_state:
    st.session_state.user_info_json = ""

# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = json.load(f)

# üîπ –ù–∞–π–¥—ë–º –Ω—É–∂–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
project_config = None
for proj in config["projects"]:
    if PROJECT_ID in proj:
        project_config = proj[PROJECT_ID]
        break

if project_config is None:
    st.error(f"–ü—Ä–æ–µ–∫—Ç —Å ID '{PROJECT_ID}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    st.stop()

allowed_users = project_config.get("allowed_users", [])
tabs_by_user = project_config.get("tabs_by_user", {})

handle_auth()

# üîπ –î–æ—Å—Ç—É–ø –∫ –¥–∞—à–±–æ—Ä–¥—É (—É—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è)
if st.session_state.login_stage == "authenticated":
    st_autorefresh(interval=3600000, limit=None, key="auto_refresh")
    st.title("üìä –î–∞—à–±–æ—Ä–¥ —Ä–∏—Å–∫–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")

    if info_file.exists():
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            st.rerun()
    else:
        st.error("‚ùå –§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–∫
    login = st.session_state.login
    available_tabs = tabs_by_user.get(login, tabs_by_user.get("default", []))

    if not available_tabs:
        st.warning("–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–∫.")
        st.stop()

    tabs = st.tabs(available_tabs)

    for tab_name, tab in zip(available_tabs, tabs):
        with tab:
            if tab_name == "–í—Å–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏":
                run_dashboard(
                    "/home/root6/python/dismissal_predict_v2/data/results/result_all.xlsx",
                    title="all",
                )
            elif tab_name == "–î—Ä—É–≥–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏":
                run_dashboard(
                    "/home/root6/python/dismissal_predict_v2/data/results/result_top.xlsx",
                    title="top",
                )
            elif tab_name == "–ü–æ –≤—Å–µ–π –∫–æ–º–ø–∞–Ω–∏–∏":
                run_dashboard_summary(
                    Path("/home/root6/python/dismissal_predict_v2/data/results/result_all.xlsx"),
                    Path(
                        "/home/root6/python/dismissal_predict_v2/data/results/result_all_shap.csv"
                    ),
                )
