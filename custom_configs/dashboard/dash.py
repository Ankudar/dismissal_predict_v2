import csv
from datetime import datetime
import json
import os
from pathlib import Path

import bcrypt
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import shap
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
import streamlit as st
import streamlit.components.v1 as components
import streamlit_authenticator as stauth
from streamlit_autorefresh import st_autorefresh

st.set_page_config(layout="wide")
CONFIG_PATH = "config.json"
PROJECT_ID = "dismissial_predict"
LOG_CSV_PATH = "auth_log.csv"


def log_auth_event_csv(login: str, status: str):
    import csv
    from datetime import datetime

    log_path = "auth_log.csv"
    headers = ["datetime", "status", "login"]
    row = [datetime.now().strftime("%Y-%m-%d %H:%M:%S"), status, login]

    write_header = not os.path.exists(log_path)
    with open(log_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(headers)
        writer.writerow(row)


if "user_info_json" not in st.session_state:
    st.session_state.user_info_json = ""


def handle_auth():
    placeholder = st.empty()

    if "login_stage" not in st.session_state:
        st.session_state.login_stage = "username"
    if "login" not in st.session_state:
        st.session_state.login = ""
    if "password_attempts" not in st.session_state:
        st.session_state.password_attempts = 0

    if st.session_state.login_stage == "username":
        with placeholder.container():
            st.title("üîê –í—Ö–æ–¥")
            login_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ª–æ–≥–∏–Ω")
            if login_input:
                if login_input not in allowed_users:
                    str_login = "fail_unknown_user"
                    log_auth_event_csv(st.session_state.login, str_login)
                    st.error("‚õî –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞")
                else:
                    st.session_state.login = login_input
                    st.session_state.login_stage = "password"
                    st.rerun()
        st.stop()

    user_record = next(
        (u for u in config["users"] if u["username"] == st.session_state.login), None
    )

    if user_record and "password" in user_record:
        if st.session_state.login_stage != "authenticated":
            with placeholder.container():
                st.title("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
                password_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å", type="password")
                if password_input:
                    if bcrypt.checkpw(
                        password_input.encode(), user_record["password"].encode("utf-8")
                    ):
                        st.session_state.login_stage = "authenticated"
                        log_auth_event_csv(st.session_state.login, "success")
                        placeholder.empty()
                        st.rerun()
                    else:
                        st.session_state.password_attempts += 1
                        str_password = "fail_wrong_password"
                        log_auth_event_csv(st.session_state.login, str_password)
                        st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
            st.stop()

    elif user_record is None:
        with placeholder.container():
            st.title("üõ° –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä–æ–ª—è")
            new_pass1 = st.text_input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø–∞—Ä–æ–ª—å", type="password")
            new_pass2 = st.text_input("–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–∞—Ä–æ–ª—å", type="password")
            if new_pass1 and new_pass2:
                if new_pass1 != new_pass2:
                    st.error("‚ùå –ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
                else:
                    hashed_pw = bcrypt.hashpw(new_pass1.encode(), bcrypt.gensalt()).decode()
                    config["users"].append(
                        {"username": st.session_state.login, "password": hashed_pw}
                    )
                    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                        json.dump(config, f, ensure_ascii=False, indent=2)

                    str_password = f"created_new_password"

                    log_auth_event_csv(st.session_state.login, str_password)

                    st.success("‚úÖ –ü–∞—Ä–æ–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
                    st.session_state.login_stage = "authenticated"
                    placeholder.empty()
                    st.rerun()
        st.stop()


# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = json.load(f)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
allowed_users = []
for project in config["projects"]:
    if project["id"] == PROJECT_ID:
        allowed_users = project.get("allowed_users", [])

handle_auth()

# –î–æ—Å—Ç—É–ø –∫ –¥–∞—à–±–æ—Ä–¥—É (—É—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è)
if st.session_state.login_stage == "authenticated":
    st_autorefresh(interval=3600000, limit=None, key="auto_refresh")
    st.title("üìä –î–∞—à–±–æ—Ä–¥ —Ä–∏—Å–∫–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")

    info_file = Path("./python/dismissal_predict_v2/data/processed/main_all.csv")

    if info_file.exists():
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    else:
        st.error("‚ùå –§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")


def run_dashboard(excel_file: str, title: str):
    if not Path(excel_file).exists():
        st.error(f"–§–∞–π–ª {excel_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    df = pd.read_excel(excel_file)
    df.columns = [str(col).strip().lower() for col in df.columns]

    # –û–ø—Ä–µ–¥–µ–ª–∏–º —Å—Ç–æ–ª–±—Ü—ã-–¥–∞—Ç—ã –∏ –ø—Ä–∏–≤–µ–¥–µ–º –∫ float
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤-–¥–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–¥.–º–º.–≥–≥–≥–≥

    date_cols = []
    new_columns = []

    for col in df.columns:
        try:
            parsed = datetime.strptime(col.strip(), "%d.%m.%Y")
            date_cols.append(col.strip())
            new_columns.append(col.strip())
        except ValueError:
            new_columns.append(col)

    df.columns = new_columns

    for col in date_cols:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", ".")
            .str.replace(" ", "")
            .str.replace(r"[^\d.]", "", regex=True)
        )
        df[col] = pd.to_numeric(df[col], errors="coerce")

    sorted_date_cols = sorted(date_cols, key=lambda d: pd.to_datetime(d, dayfirst=True))
    latest_date = sorted_date_cols[-1]

    st.subheader(f"–§–∏–ª—å—Ç—Ä—ã ({title})")
    st.info(
        """
            –í —Ç–∞–±–ª–∏—Ü–µ —Å–æ–±—Ä–∞–Ω—ã –≤—Å–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ —É–≤–æ–ª–µ–Ω–Ω—ã–µ:\n
            –§–∞–∫—Ç: 1 - –≤–∫–ª—é—á–∞–µ—Ç —É–≤–æ–ª–µ–Ω–Ω—ã—Ö, 0 - –≤–∫–ª—é—á–∞–µ—Ç –Ω–µ —É–≤–æ–ª–µ–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Å–Ω—è—Ç—å –≤—ã–±–æ—Ä, —Ç–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç.\n
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 1 - –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞, —á—Ç–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ —É–≤–æ–ª–∏—Ç—Å—è, 0 - –Ω–µ —É–≤–æ–ª–∏—Ç—Å—è.\n
            """
    )
    col_fact, col_pred = st.columns(2)

    with col_fact:
        st.markdown("**–§–∞–∫—Ç:**")
        show_0_dismissed = st.checkbox("–ù–µ —É–≤–æ–ª–µ–Ω (0)", value=True, key=f"dismissed_0_{title}")
        show_1_dismissed = st.checkbox("–£–≤–æ–ª–µ–Ω (1)", value=True, key=f"dismissed_1_{title}")

    with col_pred:
        st.markdown("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:**")
        show_0_pred = st.checkbox("–ù–µ—Ç —É–≤–æ–ª—å–Ω–µ–Ω–∏—è (0)", value=True, key=f"pred_0_{title}")
        show_1_pred = st.checkbox("–ï—Å—Ç—å —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (1)", value=True, key=f"pred_1_{title}")

    dismissed_values = []
    if show_0_dismissed:
        dismissed_values.append(0)
    if show_1_dismissed:
        dismissed_values.append(1)

    pred_values = []
    if show_0_pred:
        pred_values.append(0)
    if show_1_pred:
        pred_values.append(1)

    filtered_df = df[
        df["—É–≤–æ–ª–µ–Ω"].isin(dismissed_values) & df["–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è"].isin(pred_values)
    ]

    if info_file.exists():
        df_info = pd.read_csv(info_file)

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –§–ò–û –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
        df_info["—Ñ–∏–æ"] = df_info["—Ñ–∏–æ"].astype(str).str.strip().str.lower()
        filtered_df.loc[:, "—Ñ–∏–æ"] = filtered_df["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

        # –ú–µ—Ä–∂ –ø–æ –§–ò–û
        filtered_df = filtered_df.merge(df_info[["—Ñ–∏–æ", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å"]], how="left", on="—Ñ–∏–æ")

        # –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π:
        filtered_df = filtered_df[
            ~filtered_df["–¥–æ–ª–∂–Ω–æ—Å—Ç—å"].astype(str).str.strip().str.lower().isin(["123", "456"])
        ]
    else:
        st.warning(
            "–§–∞–π–ª —Å –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º–∏ main_all.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º –ø—Ä–æ–ø—É—â–µ–Ω–∞."
        )

    if filtered_df.empty:
        st.info("–ù–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    st.subheader(f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å —Ä–∏—Å–∫–æ–º —É–≤–æ–ª—å–Ω–µ–Ω–∏—è –Ω–∞ {latest_date}")
    st.info(
        """
            –í—ã–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ —Ä–∞–∑–≤–µ—Ä–Ω–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –Ω–∏–∂–µ.
        """
    )
    top_risk_df = (
        filtered_df.sort_values(by=latest_date, ascending=False)[["—Ñ–∏–æ", latest_date]]
        .drop_duplicates(subset="—Ñ–∏–æ", keep="first")  # <-- —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏
        .rename(columns={latest_date: "—Ä–∏—Å–∫_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è"})
        .reset_index(drop=True)
    )

    gb = GridOptionsBuilder.from_dataframe(top_risk_df)
    gb.configure_selection("single", use_checkbox=False)
    gb.configure_grid_options(autoSizeColumns=True, domLayout="normal")  # –¥–ª—è —Å–∫—Ä–æ–ª–ª–∞
    grid_options = gb.build()

    grid_response = AgGrid(
        top_risk_df,
        gridOptions=grid_options,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        height=500,
        allow_unsafe_jscode=True,
        theme="streamlit",
        fit_columns_on_grid_load=True,
    )

    selected_rows = grid_response.get("selected_rows", [])
    if isinstance(selected_rows, pd.DataFrame) and not selected_rows.empty:
        selected_fio = selected_rows.iloc[0]["—Ñ–∏–æ"]
    else:
        selected_fio = None

    if selected_fio:
        emp = df[df["—Ñ–∏–æ"] == selected_fio].iloc[0]
        st.subheader(f"–ü—Ä–æ—Ñ–∏–ª—å: {selected_fio.title()}")
        st.metric("–ò—Ç–æ–≥–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–≤–æ–ª—å–Ω–µ–Ω–∏—è", f"{emp[latest_date]*100:.1f}%")

        st.write("–î–∏–Ω–∞–º–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
        prob_series = pd.Series(emp[sorted_date_cols].values, index=sorted_date_cols)
        prob_series.index = pd.to_datetime(prob_series.index, dayfirst=True, errors="coerce")
        prob_series = prob_series.sort_index()
        st.line_chart(prob_series)

        if info_file.exists():
            info_df = pd.read_csv(info_file)

            info_df["—Ñ–∏–æ"] = info_df["—Ñ–∏–æ"].str.strip().str.lower()
            fio_lower = selected_fio.strip().lower()

            row_info = info_df[info_df["—Ñ–∏–æ"] == fio_lower]

            if not row_info.empty:
                st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ:")
                columns_to_show = [
                    "–¥–∞—Ç–∞_—É–≤–æ–ª—å–Ω–µ–Ω–∏—è",
                    "id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è",
                    "–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–µ",
                    "–¥–æ–ª–∂–Ω–æ—Å—Ç—å",
                    "–¥–∞—Ç–∞_—Ä–æ–∂–¥–µ–Ω–∏—è",
                    "–¥–∞—Ç–∞_–ø—Ä–∏–µ–º–∞_–≤_1—Å",
                    "–ø–æ–ª",
                    "—Ç–µ–∫—É—â–∞—è_–¥–æ–ª–∂–Ω–æ—Å—Ç—å_–Ω–∞_–ø–æ—Ä—Ç–∞–ª–µ",
                    "–≥—Ä–µ–π–¥",
                    "–∫–∞—Ç–µ–≥–æ—Ä–∏—è",
                    "–±–µ",
                    "–æ—Ç–¥–µ–ª",
                    "—á–∏—Å–ª–æ_–¥–µ—Ç–µ–π",
                    "—Å—Ä–µ–¥–Ω–∏–π_–≤–æ–∑—Ä–∞—Å—Ç_–¥–µ—Ç–µ–π",
                    "—Å—Ä–µ–¥–Ω–∏–π_–ø–æ–ª_–¥–µ—Ç–µ–π",
                    "—É–≤–æ–ª–µ–Ω",
                    "–≤–æ–∑—Ä–∞—Å—Ç",
                    "—Å—Ç–∞–∂",
                    "—Å–∫–æ—Ä–æ_–¥—Ä",
                    "—Å–∫–æ—Ä–æ_–≥–æ–¥–æ–≤—â–∏–∫–∞_–ø—Ä–∏–µ–º–∞",
                    "–µ—Å—Ç—å_–º–∞–ª–µ–Ω—å–∫–∏–µ_–¥–µ—Ç–∏",
                    "–∑–ø_–Ω–∞_—Å—Ä_–∑–ø_–ø–æ_–∫–æ–º–ø–∞–Ω–∏–∏",
                ]

                # –ö–æ–ø–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏
                info_display = row_info[columns_to_show].iloc[0].copy()

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è
                manager_id = info_display["id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è"]

                if pd.isna(manager_id):
                    manager_label = "nan"
                elif manager_id == -1:
                    manager_label = "-1 (nan)"
                else:
                    # –ò—â–µ–º —Ñ–∏–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ø–æ –µ–≥–æ id
                    manager_fio = info_df.loc[info_df["id"] == manager_id, "—Ñ–∏–æ"].values  # type: ignore
                    if len(manager_fio) > 0:
                        manager_label = f"{manager_id} ({manager_fio[0].title()})"
                    else:
                        manager_label = str(manager_id)

                # –ó–∞–º–µ–Ω—è–µ–º id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –Ω–∞ —Ñ–æ—Ä–º–∞—Ç —Å –§–ò–û
                info_display["id_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è"] = manager_label

                # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
                info_display = info_display.to_frame().reset_index()
                info_display.columns = ["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"]
                info_display["–ó–Ω–∞—á–µ–Ω–∏–µ"] = info_display["–ó–Ω–∞—á–µ–Ω–∏–µ"].astype(str)
                st.table(info_display)

            else:
                st.info("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ main_all.csv.")
        else:
            st.warning("–§–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        shap_file = (
            Path("./python/dismissal_predict_v2/data/results/result_top_shap.csv")
            if title == "top"
            else Path("./python/dismissal_predict_v2/data/results/result_all_shap.csv")
        )

        if shap_file.exists():
            shap_df = pd.read_csv(shap_file)
            row = shap_df[shap_df["—Ñ–∏–æ"] == selected_fio]
            if not row.empty:
                shap_row = row.iloc[0].drop("—Ñ–∏–æ")
                top_factors = shap_row.abs().sort_values(ascending=False).head(5)
                top_features = top_factors.index
                top_values = shap_row[top_features]

                st.subheader("–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ (–ø–æ SHAP):")

                col_left, col_right = st.columns([1.5, 3])

                with col_left:
                    fig, ax = plt.subplots(figsize=(6, 3.5))
                    bars = ax.barh(
                        top_features[::-1],
                        top_values[::-1],
                        color=["red" if val > 0 else "blue" for val in top_values[::-1]],
                    )
                    ax.axvline(0, color="black", linewidth=0.8)
                    ax.set_xlabel("SHAP –∑–Ω–∞—á–µ–Ω–∏–µ (–≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–∏—Å–∫)", fontsize=10)
                    ax.set_ylabel("–ü—Ä–∏–∑–Ω–∞–∫", fontsize=10)
                    ax.set_title("–¢–û–ü —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ –≤–ª–∏—è–Ω–∏—é", fontsize=11)
                    ax.tick_params(axis="both", labelsize=9)
                    fig.tight_layout()

                    st.pyplot(fig, clear_figure=True)
            else:
                st.info(f"SHAP-—Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞: {selected_fio}")
        else:
            st.info("–§–∞–π–ª —Å SHAP-—Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.")


def run_dashboard_summary(path_all, shap_path_all):
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_all = pd.read_excel(path_all)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    df_all.columns = [str(c).strip().lower() for c in df_all.columns]
    df_all["—Ñ–∏–æ"] = df_all["—Ñ–∏–æ"].astype(str).str.strip().str.lower()

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã
    date_cols = [col for col in df_all.columns if col.count(".") == 2 and col[:2].isdigit()]
    sorted_date_cols = sorted(date_cols, key=lambda d: pd.to_datetime(d, dayfirst=True))
    latest_date = sorted_date_cols[-1]

    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
    fig = px.histogram(df_all, x=latest_date, nbins=50, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è")
    fig.update_layout(xaxis_title="–†–∏—Å–∫ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è", yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
    st.plotly_chart(fig, use_container_width=True)

    # SHAP-—Ñ–∞–∫—Ç–æ—Ä—ã
    st.subheader("–ê–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞ (SHAP)")
    if shap_path_all.exists():
        shap_all = pd.read_csv(shap_path_all)

        shap_all.drop(columns=["—Ñ–∏–æ"], inplace=True, errors="ignore")

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        mean_positive = (
            shap_all[shap_all > 0].mean().dropna().sort_values(ascending=False).head(10)
        )
        mean_negative = shap_all[shap_all < 0].mean().dropna().sort_values().head(10)

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**–¢–û–ü-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (SHAP > 0)**")
            fig1 = px.bar(
                mean_positive.reset_index(),
                x="index",
                y=0,
                labels={"index": "–§–∞–∫—Ç–æ—Ä", "0": "SHAP –∑–Ω–∞—á–µ–Ω–∏–µ"},
            )
            fig1.update_layout(xaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            st.markdown("**–¢–û–ü-10 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–∞ –Ω–µ—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ (SHAP < 0)**")
            fig2 = px.bar(
                mean_negative.reset_index(),
                x="index",
                y=0,
                labels={"index": "–§–∞–∫—Ç–æ—Ä", "0": "SHAP –∑–Ω–∞—á–µ–Ω–∏–µ"},
            )
            fig2.update_layout(xaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig2, use_container_width=True)

        with col3:
            st.markdown("**–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ (–ø–æ SHAP)**")
            top_features = (
                shap_all.abs().mean().sort_values(ascending=False).head(10).index.tolist()
            )
            shap_sample = shap_all[top_features]

            fig_summary, ax = plt.subplots(figsize=(8, 6))
            shap.summary_plot(
                shap_sample.values,
                features=shap_sample,
                feature_names=top_features,
                plot_type="dot",
                show=False,
            )
            st.pyplot(fig_summary)
    else:
        st.warning("–§–∞–π–ª SHAP-—Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")


# –í–∫–ª–∞–¥–∫–∏
tab1, tab2, tab3 = st.tabs(["–í—Å–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", "–î—Ä—É–≥–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", "–ü–æ –≤—Å–µ–π –∫–æ–º–ø–∞–Ω–∏–∏"])

with tab1:
    run_dashboard(
        "./python/dismissal_predict_v2/data/results/result_all.xlsx",
        title="all",
    )

with tab2:
    run_dashboard(
        "./python/dismissal_predict_v2/data/results/result_top.xlsx",
        title="top",
    )

with tab3:
    run_dashboard_summary(
        Path("./python/dismissal_predict_v2/data/results/result_all.xlsx"),
        Path("./python/dismissal_predict_v2/data/results/result_all_shap.csv"),
    )
